#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹å®Œæ•´å·¥ä½œæµ
åŸºäºé˜ˆå€¼çªç ´æ³•ï¼Œæ‰¾å‡ºé•¿æœŸä½é‡åçªç„¶æ”¾é‡çš„çŸ­çº¿æœºä¼š
"""

import requests
import re
import json
import time
import random
import logging
import pandas as pd
import statistics
from datetime import datetime
import concurrent.futures
import threading

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('volume_anomaly_workflow.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VolumeAnomalyWorkflow:
    def __init__(self, request_delay=0.1, max_workers=5):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.request_delay = request_delay
        self.max_workers = max_workers
        self.session = requests.Session()
        
        # User-Agentæ± 
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        ]
        
        self._update_session_headers()
        
        # å­˜å‚¨ç»“æœ
        self.anomaly_stocks = []
        self.processed_count = 0
        self.start_time = time.time()
        
        # æ£€æµ‹å‚æ•°ï¼ˆä¼˜åŒ–åçš„æ ‡å‡†ï¼‰
        self.strict_threshold = 0.5     # ä¸¥æ ¼æ¨¡å¼ï¼šä»Šæ—¥é‡çš„50%
        self.loose_threshold = 0.6      # å®½æ¾æ¨¡å¼ï¼šä»Šæ—¥é‡çš„60%
        self.recent_days = 15           # é‡ç‚¹å…³æ³¨æœ€è¿‘15å¤©
        self.min_volume = 5.0           # æœ€å°æˆäº¤é‡5ä¸‡æ‰‹
        self.min_change_pct = 0.3       # æœ€å°æ¶¨å¹…0.3%
        
        # çº¿ç¨‹é”
        self.lock = threading.Lock()
    
    def _get_random_user_agent(self):
        """è·å–éšæœºUser-Agent"""
        return random.choice(self.user_agents)
    
    def _update_session_headers(self):
        """æ›´æ–°session headers"""
        self.session.headers.update({
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'application/javascript, */*;q=0.1',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'http://quote.eastmoney.com/',
        })
    
    def _random_delay(self):
        """éšæœºå»¶è¿Ÿ"""
        delay = random.uniform(self.request_delay * 0.8, self.request_delay * 1.2)
        time.sleep(delay)
    
    def _extract_jsonp_data(self, response_text):
        """ä»JSONPå“åº”ä¸­æå–JSONæ•°æ®"""
        try:
            pattern = r'[a-zA-Z_$][a-zA-Z0-9_$]*\((.*)\)'
            match = re.search(pattern, response_text)
            if match:
                json_str = match.group(1)
                return json.loads(json_str)
            return None
        except Exception as e:
            logger.debug(f"è§£æJSONPæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def _show_progress(self, current, total, extra_info=""):
        """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        if current > 0:
            eta = (elapsed / current) * (total - current)
            eta_str = f"é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ"
        else:
            eta_str = "è®¡ç®—ä¸­..."
        
        percentage = (current / total) * 100 if total > 0 else 0
        
        # æ¯50ä¸ªæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼Œæˆ–è€…å‘ç°å¼‚å¸¸æ—¶æ˜¾ç¤º
        if current % 50 == 0 or "å‘ç°å¼‚å¸¸" in extra_info or current == total:
            logger.info(f"ğŸ“Š è¿›åº¦: {current}/{total} ({percentage:.1f}%) | ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | {eta_str} | {extra_info}")
            
            # å¦‚æœæ˜¯å‘ç°å¼‚å¸¸ï¼Œä¹Ÿåœ¨æ§åˆ¶å°æ˜¾ç¤º
            if "å‘ç°å¼‚å¸¸" in extra_info:
                print(f"ğŸš¨ {extra_info}")
    
    def get_shanghai_a_stocks(self):
        """è·å–æ‰€æœ‰ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨"""
        try:
            logger.info("ğŸ” å¼€å§‹è·å–ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            all_stocks = []
            
            # è·å–æ€»é¡µæ•°
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            url = "https://push2.eastmoney.com/api/qt/clist/get"
            params = {
                'np': '1',
                'fltt': '1',
                'invt': '2',
                'cb': callback,
                'fs': 'm:1+t:2,m:1+t:23',  # ä¸Šæµ·Aè‚¡
                'fields': 'f12,f13,f14,f1,f2,f4,f3,f152,f5,f6,f7,f15,f18,f16,f17,f10,f8,f9,f23',
                'fid': 'f3',
                'pn': '1',
                'pz': '50',
                'po': '1',
                'dect': '1',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'wbp2u': f'{random.randint(10**15, 10**16-1)}|0|1|0|web',
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=15)
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                logger.error("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
                return []
            
            total_count = data.get('data', {}).get('total', 0)
            page_size = 50
            total_pages = (total_count + page_size - 1) // page_size
            
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_count}, æ€»é¡µæ•°: {total_pages}")
            
            # è·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®
            for page in range(1, min(total_pages + 1, 50)):  # é™åˆ¶æœ€å¤š50é¡µï¼ŒåŠ å¿«é€Ÿåº¦
                try:
                    if page % 10 == 1:
                        logger.info(f"ğŸ“„ è·å–è‚¡ç¥¨åˆ—è¡¨ç¬¬ {page}/{min(total_pages, 50)} é¡µ...")
                    
                    timestamp = int(time.time() * 1000)
                    callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
                    
                    params.update({
                        'cb': callback,
                        'pn': str(page),
                        '_': str(timestamp + random.randint(1, 100))
                    })
                    
                    response = self.session.get(url, params=params, timeout=15)
                    response.raise_for_status()
                    
                    data = self._extract_jsonp_data(response.text)
                    if not data or data.get('rc') != 0:
                        logger.warning(f"ç¬¬ {page} é¡µæ•°æ®è·å–å¤±è´¥")
                        continue
                    
                    stocks = data.get('data', {}).get('diff', [])
                    
                    for stock in stocks:
                        stock_code = stock.get('f12', '')
                        stock_name = stock.get('f14', '')
                        current_price = stock.get('f2', 0) / 100 if stock.get('f2') else 0
                        change_pct = stock.get('f3', 0) / 100 if stock.get('f3') else 0
                        volume = stock.get('f5', 0)
                        turnover = stock.get('f6', 0)
                        
                        if stock_code and stock_name:
                            stock_info = {
                                'code': stock_code,
                                'name': stock_name,
                                'current_price': current_price,
                                'change_pct': change_pct,
                                'today_volume': volume / 100,  # è½¬æ¢ä¸ºä¸‡æ‰‹
                                'turnover': turnover
                            }
                            all_stocks.append(stock_info)
                    
                    time.sleep(0.05)  # çŸ­æš‚å»¶è¿Ÿ
                    
                except Exception as e:
                    logger.error(f"è·å–ç¬¬ {page} é¡µå¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(all_stocks)} åªä¸Šæµ·Aè‚¡")
            return all_stocks
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šæµ·Aè‚¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def get_stock_kline_data(self, stock_code, days=61):
        """è·å–è‚¡ç¥¨Kçº¿æ•°æ®"""
        try:
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                'fields1': 'f1,f2,f3,f4,f5',
                'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61',
                'fqt': '1',
                'end': '29991010',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'cb': callback,
                'klt': '101',
                'secid': f'1.{stock_code}',
                'lmt': str(days),
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                return []
            
            klines = data.get('data', {}).get('klines', [])
            
            parsed_data = []
            for kline in klines:
                parts = kline.split(',')
                if len(parts) >= 6:
                    try:
                        date = parts[0]
                        volume = float(parts[5]) / 100  # è½¬æ¢ä¸ºä¸‡æ‰‹
                        parsed_data.append({
                            'date': date,
                            'volume': volume
                        })
                    except (ValueError, IndexError):
                        continue
            
            return parsed_data
            
        except Exception as e:
            logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} Kçº¿æ•°æ®å¤±è´¥: {str(e)}")
            return []
    
    def analyze_volume_anomaly(self, stock_info):
        """åˆ†æå•åªè‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            stock_code = stock_info['code']
            stock_name = stock_info['name']
            today_volume = stock_info['today_volume']
            
            # è¿‡æ»¤æˆäº¤é‡å¤ªå°çš„è‚¡ç¥¨
            if today_volume < self.min_volume:
                return None
            
            # è¿‡æ»¤æ¶¨å¹…ä¸å¤Ÿçš„è‚¡ç¥¨
            if stock_info['change_pct'] < self.min_change_pct:
                return None
            
            # è·å–å†å²Kçº¿æ•°æ®
            kline_data = self.get_stock_kline_data(stock_code, days=61)
            
            if len(kline_data) < 61:
                return None
            
            # æ•°æ®åˆ†ç¦»ï¼šå‰60å¤©å†å² + ä»Šå¤©
            historical_60 = kline_data[:-1]
            today_data = kline_data[-1]
            
            # è®¾å®šé˜ˆå€¼
            strict_threshold = today_volume * self.strict_threshold
            loose_threshold = today_volume * self.loose_threshold
            
            # æ£€æŸ¥å†å²çªç ´æƒ…å†µ
            over_strict_days = [d for d in historical_60 if d['volume'] > strict_threshold]
            over_loose_days = [d for d in historical_60 if d['volume'] > loose_threshold]
            
            # æ£€æŸ¥æœ€è¿‘15å¤©çš„æƒ…å†µ
            recent_15 = historical_60[-self.recent_days:]
            over_strict_recent = [d for d in recent_15 if d['volume'] > strict_threshold]
            over_loose_recent = [d for d in recent_15 if d['volume'] > loose_threshold]
            
            # ä¼˜åŒ–çš„å¼‚å¸¸åˆ¤æ–­æ ‡å‡†
            # æ–¹æ¡ˆ1ï¼šä¸¥æ ¼æ¨¡å¼ - å‰60å¤©å®Œå…¨æ²¡è¶…è¿‡50%é˜ˆå€¼
            is_strict_anomaly = len(over_strict_days) == 0
            
            # æ–¹æ¡ˆ2ï¼šå®½æ¾æ¨¡å¼ - å‰60å¤©â‰¤2å¤©è¶…è¿‡60%é˜ˆå€¼ ä¸” æœ€è¿‘15å¤©â‰¤1å¤©è¶…è¿‡50%é˜ˆå€¼
            is_loose_anomaly = (
                len(over_loose_days) <= 2 and
                len(over_strict_recent) <= 1
            )
            
            # æ–¹æ¡ˆ3ï¼šè¿‘æœŸçªç ´ - æœ€è¿‘15å¤©æ²¡è¶…è¿‡é˜ˆå€¼ï¼Œä»Šå¤©çªç ´
            is_recent_breakthrough = len(over_strict_recent) == 0
            
            # ç»¼åˆåˆ¤æ–­
            is_anomaly = is_strict_anomaly or is_loose_anomaly or is_recent_breakthrough
            
            if is_anomaly:
                # è®¡ç®—å¼‚å¸¸è¯„åˆ†
                historical_max = max(d['volume'] for d in historical_60)
                recent_max = max(d['volume'] for d in recent_15)
                
                # è¯„åˆ†å› å­
                breakthrough_score = 0
                if is_strict_anomaly:
                    breakthrough_score += 50  # ä¸¥æ ¼çªç ´æœ€é«˜åˆ†
                if is_recent_breakthrough:
                    breakthrough_score += 30  # è¿‘æœŸçªç ´åŠ åˆ†
                if is_loose_anomaly:
                    breakthrough_score += 20  # å®½æ¾çªç ´åŸºç¡€åˆ†
                
                volume_score = min(30, (today_volume / strict_threshold) * 10)  # æˆäº¤é‡å€æ•°åˆ†
                price_score = min(20, stock_info['change_pct'] * 5)  # æ¶¨å¹…åˆ†
                
                anomaly_score = breakthrough_score + volume_score + price_score
                
                # åˆ¤æ–­å¼‚å¸¸ç±»å‹
                anomaly_type = []
                if is_strict_anomaly:
                    anomaly_type.append("ä¸¥æ ¼çªç ´")
                if is_recent_breakthrough:
                    anomaly_type.append("è¿‘æœŸçªç ´")
                if is_loose_anomaly:
                    anomaly_type.append("å®½æ¾çªç ´")
                
                anomaly_info = {
                    'code': stock_code,
                    'name': stock_name,
                    'current_price': stock_info['current_price'],
                    'change_pct': stock_info['change_pct'],
                    'today_volume': today_volume,
                    'strict_threshold': strict_threshold,
                    'loose_threshold': loose_threshold,
                    'historical_max': historical_max,
                    'recent_max': recent_max,
                    'over_strict_days': len(over_strict_days),
                    'over_loose_days': len(over_loose_days),
                    'over_strict_recent': len(over_strict_recent),
                    'anomaly_score': anomaly_score,
                    'anomaly_type': ','.join(anomaly_type),
                    'turnover': stock_info['turnover'],
                    'is_historical_high': today_volume > historical_max
                }
                
                return anomaly_info
            
            return None
            
        except Exception as e:
            logger.debug(f"åˆ†æè‚¡ç¥¨ {stock_info.get('code', 'unknown')} å¼‚å¸¸å¤±è´¥: {str(e)}")
            return None
    
    def process_single_stock(self, stock):
        """å¤„ç†å•åªè‚¡ç¥¨"""
        try:
            anomaly = self.analyze_volume_anomaly(stock)
            
            with self.lock:
                self.processed_count += 1
                
                if anomaly:
                    self.anomaly_stocks.append(anomaly)
                    extra_info = f"å‘ç°å¼‚å¸¸: {anomaly['name']}({anomaly['code']}) - è¯„åˆ†:{anomaly['anomaly_score']:.1f}"
                    self._show_progress(self.processed_count, len(self.all_stocks), extra_info)
                else:
                    if self.processed_count % 50 == 0:
                        self._show_progress(self.processed_count, len(self.all_stocks))
                
                self._random_delay()
                
        except Exception as e:
            logger.debug(f"å¤„ç†è‚¡ç¥¨å¤±è´¥: {str(e)}")
    
    def detect_all_anomalies(self, limit=None):
        """æ£€æµ‹æ‰€æœ‰è‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ£€æµ‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸...")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            self.all_stocks = self.get_shanghai_a_stocks()
            if not self.all_stocks:
                logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return
            
            # é¢„ç­›é€‰ï¼šä¼˜å…ˆæ£€æµ‹æ´»è·ƒè‚¡ç¥¨
            active_stocks = [s for s in self.all_stocks if s.get('today_volume', 0) >= self.min_volume and s.get('change_pct', 0) >= self.min_change_pct]
            active_stocks.sort(key=lambda x: x.get('today_volume', 0), reverse=True)
            
            # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            if limit:
                active_stocks = active_stocks[:limit]
                logger.info(f"âš¡ æµ‹è¯•æ¨¡å¼ï¼šé™åˆ¶å¤„ç†å‰ {limit} åªè‚¡ç¥¨")
            
            logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ {len(active_stocks)} åªæ´»è·ƒè‚¡ç¥¨...")
            self.all_stocks = active_stocks  # æ›´æ–°å¼•ç”¨
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = [executor.submit(self.process_single_stock, stock) for stock in active_stocks]
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                concurrent.futures.wait(futures)
            
            # æŒ‰å¼‚å¸¸è¯„åˆ†æ’åº
            self.anomaly_stocks.sort(key=lambda x: x['anomaly_score'], reverse=True)
            
            elapsed_time = time.time() - self.start_time
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼ç”¨æ—¶ {elapsed_time/60:.1f} åˆ†é’Ÿ")
            logger.info(f"ğŸ“Š å…±åˆ†æ {self.processed_count} åªè‚¡ç¥¨ï¼Œå‘ç° {len(self.anomaly_stocks)} åªå¼‚å¸¸è‚¡ç¥¨")
            
        except Exception as e:
            logger.error(f"æ£€æµ‹æˆäº¤é‡å¼‚å¸¸å¤±è´¥: {str(e)}")
    
    def save_results(self, filename=None):
        """ä¿å­˜æ£€æµ‹ç»“æœ"""
        try:
            if not self.anomaly_stocks:
                logger.warning("æ²¡æœ‰å¼‚å¸¸è‚¡ç¥¨æ•°æ®å¯ä¿å­˜")
                return None
            
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨_{timestamp}.xlsx"
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(self.anomaly_stocks)
            
            # é‡å‘½ååˆ—
            column_names = {
                'code': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'current_price': 'å½“å‰ä»·æ ¼',
                'change_pct': 'æ¶¨è·Œå¹…(%)',
                'today_volume': 'ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)',
                'strict_threshold': 'ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)',
                'loose_threshold': 'å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)',
                'historical_max': '60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)',
                'recent_max': '15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)',
                'over_strict_days': 'è¶…ä¸¥æ ¼é˜ˆå€¼å¤©æ•°',
                'over_loose_days': 'è¶…å®½æ¾é˜ˆå€¼å¤©æ•°',
                'over_strict_recent': 'è¿‘æœŸè¶…é˜ˆå€¼å¤©æ•°',
                'anomaly_score': 'å¼‚å¸¸è¯„åˆ†',
                'anomaly_type': 'å¼‚å¸¸ç±»å‹',
                'is_historical_high': 'æ˜¯å¦åˆ›æ–°é«˜',
                'turnover': 'æˆäº¤é¢(å…ƒ)'
            }
            
            df = df.rename(columns=column_names)
            
            # æ ¼å¼åŒ–æ•°å€¼æ˜¾ç¤º
            df['æ¶¨è·Œå¹…(%)'] = df['æ¶¨è·Œå¹…(%)'].round(2)
            df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'] = df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'].round(1)
            df['ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)'] = df['ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)'].round(1)
            df['å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)'] = df['å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)'].round(1)
            df['60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'] = df['60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'].round(1)
            df['15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'] = df['15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'].round(1)
            df['å¼‚å¸¸è¯„åˆ†'] = df['å¼‚å¸¸è¯„åˆ†'].round(1)
            
            # ä¿å­˜åˆ°Excel
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨', index=False)
                
                # è°ƒæ•´åˆ—å®½
                worksheet = writer.sheets['æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨']
                for column in worksheet.columns:
                    max_length = 0
                    column = [cell for cell in column]
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 25)
                    worksheet.column_dimensions[column[0].column_letter].width = adjusted_width
            
            logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def print_summary(self):
        """æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦"""
        if not self.anomaly_stocks:
            logger.info("ğŸ“Š æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å¼‚å¸¸æˆäº¤é‡è‚¡ç¥¨")
            return
        
        logger.info("ğŸ“Š æˆäº¤é‡å¼‚å¸¸æ£€æµ‹ç»“æœæ‘˜è¦:")
        logger.info(f"   ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°é‡: {len(self.anomaly_stocks)}")
        
        # ç»Ÿè®¡å¼‚å¸¸ç±»å‹
        type_count = {}
        for stock in self.anomaly_stocks:
            types = stock['anomaly_type'].split(',')
            for t in types:
                type_count[t] = type_count.get(t, 0) + 1
        
        logger.info(f"   å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
        for anomaly_type, count in type_count.items():
            logger.info(f"     {anomaly_type}: {count}åª")
        
        # æ˜¾ç¤ºå‰10åªå¼‚å¸¸è¯„åˆ†æœ€é«˜çš„è‚¡ç¥¨
        top_stocks = self.anomaly_stocks[:10]
        logger.info("\nğŸ† å¼‚å¸¸è¯„åˆ†TOP10è‚¡ç¥¨:")
        
        for i, stock in enumerate(top_stocks, 1):
            logger.info(f"   {i:2d}. {stock['name']}({stock['code']})")
            logger.info(f"       ä»·æ ¼: {stock['current_price']:.2f}å…ƒ æ¶¨å¹…: {stock['change_pct']:+.2f}%")
            logger.info(f"       ä»Šæ—¥é‡: {stock['today_volume']:.1f}ä¸‡æ‰‹ | é˜ˆå€¼: {stock['strict_threshold']:.1f}ä¸‡æ‰‹")
            logger.info(f"       ç±»å‹: {stock['anomaly_type']} | è¯„åˆ†: {stock['anomaly_score']:.1f}")
            if stock['is_historical_high']:
                logger.info(f"       ğŸ”¥ åˆ›60å¤©æ–°é«˜ï¼")
        
        # ç»Ÿè®¡ä¿¡æ¯
        avg_score = sum(s['anomaly_score'] for s in self.anomaly_stocks) / len(self.anomaly_stocks)
        max_score = max(s['anomaly_score'] for s in self.anomaly_stocks)
        
        logger.info(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   å¹³å‡å¼‚å¸¸è¯„åˆ†: {avg_score:.1f}")
        logger.info(f"   æœ€é«˜å¼‚å¸¸è¯„åˆ†: {max_score:.1f}")
        logger.info(f"   åˆ›æ–°é«˜è‚¡ç¥¨æ•°: {sum(1 for s in self.anomaly_stocks if s['is_historical_high'])}åª")

def main():
    """ä¸»å‡½æ•°"""
    workflow = VolumeAnomalyWorkflow(request_delay=0.1, max_workers=3)
    
    try:
        logger.info("ğŸš€ å¼€å§‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹å·¥ä½œæµ...")
        
        # æ£€æµ‹æ‰€æœ‰å¼‚å¸¸
        # æµ‹è¯•æ—¶å¯ä»¥è®¾ç½®limit=100é™åˆ¶æ•°é‡ï¼Œæ­£å¼è¿è¡Œæ—¶å»æ‰limitå‚æ•°
        workflow.detect_all_anomalies(limit=200)  # æµ‹è¯•200åªæ´»è·ƒè‚¡ç¥¨
        
        # æ‰“å°æ‘˜è¦
        workflow.print_summary()
        
        # ä¿å­˜ç»“æœ
        filename = workflow.save_results()
        
        if filename:
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        # å³ä½¿ä¸­æ–­ä¹Ÿä¿å­˜å·²å¤„ç†çš„ç»“æœ
        if workflow.anomaly_stocks:
            filename = workflow.save_results()
            logger.info(f"ğŸ’¾ å·²ä¿å­˜éƒ¨åˆ†ç»“æœåˆ°: {filename}")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()