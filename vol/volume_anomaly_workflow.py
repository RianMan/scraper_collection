#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹å®Œæ•´å·¥ä½œæµ - å¸¦å›¾è¡¨ç”Ÿæˆç‰ˆæœ¬
åŸºäºé˜ˆå€¼çªç ´æ³•ï¼Œæ‰¾å‡ºé•¿æœŸä½é‡åçªç„¶æ”¾é‡çš„çŸ­çº¿æœºä¼š
ä¿®å¤äº†å­—ç¬¦ä¸²é™¤æ³•çš„ç±»å‹é”™è¯¯é—®é¢˜
æ–°å¢ï¼šä¸ºå¼‚å¸¸è‚¡ç¥¨è‡ªåŠ¨ç”Ÿæˆæˆäº¤é‡æŸ±çŠ¶å›¾
"""

import requests
import re
import json
import time
import random
import logging
import pandas as pd
import statistics
from datetime import datetime
import concurrent.futures
import threading
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.font_manager import FontProperties
import os

# é…ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('volume_anomaly_workflow.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VolumeAnomalyWorkflow:
    def __init__(self, request_delay=0.1, max_workers=5):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.request_delay = request_delay
        self.max_workers = max_workers
        self.session = requests.Session()
        
        # User-Agentæ± 
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        ]
        
        self._update_session_headers()
        
        # å­˜å‚¨ç»“æœ
        self.anomaly_stocks = []
        self.processed_count = 0
        self.start_time = time.time()
        
        # æ£€æµ‹å‚æ•°ï¼ˆä¼˜åŒ–åçš„æ ‡å‡†ï¼‰
        self.strict_threshold = 0.5     # ä¸¥æ ¼æ¨¡å¼ï¼šä»Šæ—¥é‡çš„50%
        self.loose_threshold = 0.6      # å®½æ¾æ¨¡å¼ï¼šä»Šæ—¥é‡çš„60%
        self.recent_days = 15           # é‡ç‚¹å…³æ³¨æœ€è¿‘15å¤©
        self.min_volume = 5.0           # æœ€å°æˆäº¤é‡5ä¸‡æ‰‹
        self.min_change_pct = 0.3       # æœ€å°æ¶¨å¹…0.3%
        
        # çº¿ç¨‹é”
        self.lock = threading.Lock()
        
        # å›¾è¡¨å­˜å‚¨ç›®å½•
        self.chart_dir = "volume_charts"
        if not os.path.exists(self.chart_dir):
            os.makedirs(self.chart_dir)
    
    def _safe_float_division(self, value, divisor, default=0.0):
        """å®‰å…¨çš„æµ®ç‚¹æ•°é™¤æ³•ï¼Œå¤„ç†å­—ç¬¦ä¸²å’Œå¼‚å¸¸å€¼"""
        try:
            if value is None:
                return default
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(value, str):
                # å¤„ç†å¸¸è§çš„éæ•°å­—å­—ç¬¦ä¸²
                if value in ['--', 'N/A', '', 'null', 'undefined']:
                    return default
                # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                value = float(value)
            
            # ç¡®ä¿é™¤æ•°ä¸ä¸º0
            if divisor == 0:
                return default
                
            return float(value) / float(divisor)
            
        except (ValueError, TypeError, ZeroDivisionError) as e:
            logger.debug(f"æ•°å€¼è½¬æ¢å¤±è´¥: {value} / {divisor}, é”™è¯¯: {str(e)}")
            return default
    
    def _safe_float_conversion(self, value, default=0.0):
        """å®‰å…¨çš„æµ®ç‚¹æ•°è½¬æ¢"""
        try:
            if value is None:
                return default
                
            if isinstance(value, str):
                if value in ['--', 'N/A', '', 'null', 'undefined']:
                    return default
                return float(value)
                
            return float(value)
            
        except (ValueError, TypeError) as e:
            logger.debug(f"æ•°å€¼è½¬æ¢å¤±è´¥: {value}, é”™è¯¯: {str(e)}")
            return default
    
    def _get_random_user_agent(self):
        """è·å–éšæœºUser-Agent"""
        return random.choice(self.user_agents)
    
    def _update_session_headers(self):
        """æ›´æ–°session headers"""
        self.session.headers.update({
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'application/javascript, */*;q=0.1',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'http://quote.eastmoney.com/',
        })
    
    def _random_delay(self):
        """éšæœºå»¶è¿Ÿ"""
        delay = random.uniform(self.request_delay * 0.8, self.request_delay * 1.2)
        time.sleep(delay)
    
    def _extract_jsonp_data(self, response_text):
        """ä»JSONPå“åº”ä¸­æå–JSONæ•°æ®"""
        try:
            pattern = r'[a-zA-Z_$][a-zA-Z0-9_$]*\((.*)\)'
            match = re.search(pattern, response_text)
            if match:
                json_str = match.group(1)
                return json.loads(json_str)
            return None
        except Exception as e:
            logger.debug(f"è§£æJSONPæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def _show_progress(self, current, total, extra_info=""):
        """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        if current > 0:
            eta = (elapsed / current) * (total - current)
            eta_str = f"é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ"
        else:
            eta_str = "è®¡ç®—ä¸­..."
        
        percentage = (current / total) * 100 if total > 0 else 0
        
        # æ¯50ä¸ªæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼Œæˆ–è€…å‘ç°å¼‚å¸¸æ—¶æ˜¾ç¤º
        if current % 50 == 0 or "å‘ç°å¼‚å¸¸" in extra_info or current == total:
            logger.info(f"ğŸ“Š è¿›åº¦: {current}/{total} ({percentage:.1f}%) | ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | {eta_str} | {extra_info}")
            
            # å¦‚æœæ˜¯å‘ç°å¼‚å¸¸ï¼Œä¹Ÿåœ¨æ§åˆ¶å°æ˜¾ç¤º
            if "å‘ç°å¼‚å¸¸" in extra_info:
                print(f"ğŸš¨ {extra_info}")
    
    def get_shanghai_a_stocks(self):
        """è·å–æ‰€æœ‰ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨"""
        try:
            logger.info("ğŸ” å¼€å§‹è·å–ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            all_stocks = []
            
            # è·å–æ€»é¡µæ•°
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            url = "https://push2.eastmoney.com/api/qt/clist/get"
            params = {
                'np': '1',
                'fltt': '1',
                'invt': '2',
                'cb': callback,
                'fs': 'm:1+t:2,m:1+t:23',  # ä¸Šæµ·Aè‚¡
                'fields': 'f12,f13,f14,f1,f2,f4,f3,f152,f5,f6,f7,f15,f18,f16,f17,f10,f8,f9,f23',
                'fid': 'f3',
                'pn': '1',
                'pz': '50',
                'po': '1',
                'dect': '1',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'wbp2u': f'{random.randint(10**15, 10**16-1)}|0|1|0|web',
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=15)
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                logger.error("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
                return []
            
            total_count = data.get('data', {}).get('total', 0)
            page_size = 50
            total_pages = (total_count + page_size - 1) // page_size
            
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_count}, æ€»é¡µæ•°: {total_pages}")
            
            # è·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®
            for page in range(1, min(total_pages + 1, 50)):  # é™åˆ¶æœ€å¤š50é¡µï¼ŒåŠ å¿«é€Ÿåº¦
                try:
                    if page % 10 == 1:
                        logger.info(f"ğŸ“„ è·å–è‚¡ç¥¨åˆ—è¡¨ç¬¬ {page}/{min(total_pages, 50)} é¡µ...")
                    
                    timestamp = int(time.time() * 1000)
                    callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
                    
                    params.update({
                        'cb': callback,
                        'pn': str(page),
                        '_': str(timestamp + random.randint(1, 100))
                    })
                    
                    response = self.session.get(url, params=params, timeout=15)
                    response.raise_for_status()
                    
                    data = self._extract_jsonp_data(response.text)
                    if not data or data.get('rc') != 0:
                        logger.warning(f"ç¬¬ {page} é¡µæ•°æ®è·å–å¤±è´¥")
                        continue
                    
                    stocks = data.get('data', {}).get('diff', [])
                    
                    for stock in stocks:
                        try:
                            stock_code = stock.get('f12', '')
                            stock_name = stock.get('f14', '')
                            
                            # ä½¿ç”¨å®‰å…¨çš„æ•°å€¼è½¬æ¢
                            current_price = self._safe_float_division(stock.get('f2', 0), 100, 0.0)
                            change_pct = self._safe_float_division(stock.get('f3', 0), 100, 0.0)
                            volume = self._safe_float_conversion(stock.get('f5', 0), 0.0)
                            turnover = self._safe_float_conversion(stock.get('f6', 0), 0.0)
                            
                            if stock_code and stock_name:
                                stock_info = {
                                    'code': stock_code,
                                    'name': stock_name,
                                    'current_price': current_price,
                                    'change_pct': change_pct,
                                    'today_volume': volume / 100,  # è½¬æ¢ä¸ºä¸‡æ‰‹
                                    'turnover': turnover
                                }
                                all_stocks.append(stock_info)
                                
                        except Exception as e:
                            logger.debug(f"å¤„ç†è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}, è‚¡ç¥¨æ•°æ®: {stock}")
                            continue
                    
                    time.sleep(0.05)  # çŸ­æš‚å»¶è¿Ÿ
                    
                except Exception as e:
                    logger.error(f"è·å–ç¬¬ {page} é¡µå¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(all_stocks)} åªä¸Šæµ·Aè‚¡")
            return all_stocks
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šæµ·Aè‚¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def get_stock_kline_data(self, stock_code, days=61):
        """è·å–è‚¡ç¥¨Kçº¿æ•°æ®"""
        try:
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                'fields1': 'f1,f2,f3,f4,f5',
                'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61',
                'fqt': '1',
                'end': '29991010',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'cb': callback,
                'klt': '101',
                'secid': f'1.{stock_code}',
                'lmt': str(days),
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                return []
            
            klines = data.get('data', {}).get('klines', [])
            
            parsed_data = []
            for kline in klines:
                parts = kline.split(',')
                if len(parts) >= 6:
                    try:
                        date = parts[0]
                        volume = self._safe_float_division(parts[5], 100, 0.0)  # å®‰å…¨è½¬æ¢ä¸ºä¸‡æ‰‹
                        parsed_data.append({
                            'date': date,
                            'volume': volume
                        })
                    except (ValueError, IndexError) as e:
                        logger.debug(f"è§£æKçº¿æ•°æ®å¤±è´¥: {str(e)}, æ•°æ®: {parts}")
                        continue
            
            return parsed_data
            
        except Exception as e:
            logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} Kçº¿æ•°æ®å¤±è´¥: {str(e)}")
            return []
    
    def generate_volume_chart(self, stock_info, kline_data):
        """ä¸ºå•åªè‚¡ç¥¨ç”Ÿæˆæˆäº¤é‡æŸ±çŠ¶å›¾"""
        try:
            stock_code = stock_info['code']
            stock_name = stock_info['name']
            
            # è·å–æœ€è¿‘30å¤©æ•°æ®
            recent_30 = kline_data[-31:]  # åŒ…æ‹¬ä»Šå¤©
            if len(recent_30) < 30:
                logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³30å¤©ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
                return None
            
            # å‡†å¤‡æ•°æ®
            dates = [datetime.strptime(d['date'], '%Y-%m-%d') for d in recent_30]
            volumes = [d['volume'] for d in recent_30]
            
            # è®¡ç®—é˜ˆå€¼çº¿
            today_volume = volumes[-1]
            strict_threshold = today_volume * self.strict_threshold
            loose_threshold = today_volume * self.loose_threshold
            avg_volume = sum(volumes[:-1]) / len(volumes[:-1])  # å‰29å¤©å¹³å‡å€¼
            
            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(12, 6))
            
            # ç»˜åˆ¶æˆäº¤é‡æŸ±çŠ¶å›¾
            colors = []
            for i, vol in enumerate(volumes):
                if i == len(volumes) - 1:  # ä»Šå¤©
                    colors.append('#FF4444')  # çº¢è‰²çªå‡ºä»Šå¤©
                elif vol > strict_threshold:
                    colors.append('#FF8888')  # æµ…çº¢è‰²è¡¨ç¤ºè¶…è¿‡ä¸¥æ ¼é˜ˆå€¼
                elif vol > avg_volume:
                    colors.append('#88BB88')  # ç»¿è‰²è¡¨ç¤ºé«˜äºå¹³å‡
                else:
                    colors.append('#BBBBBB')  # ç°è‰²è¡¨ç¤ºæ­£å¸¸
            
            bars = ax.bar(dates, volumes, color=colors, alpha=0.8, width=0.8)
            
            # æ·»åŠ é˜ˆå€¼çº¿
            ax.axhline(y=strict_threshold, color='red', linestyle='--', alpha=0.7, 
                      label=f'ä¸¥æ ¼é˜ˆå€¼ ({strict_threshold:.1f}ä¸‡æ‰‹)')
            ax.axhline(y=loose_threshold, color='orange', linestyle='--', alpha=0.7,
                      label=f'å®½æ¾é˜ˆå€¼ ({loose_threshold:.1f}ä¸‡æ‰‹)')
            ax.axhline(y=avg_volume, color='blue', linestyle='-', alpha=0.5,
                      label=f'29å¤©å‡é‡ ({avg_volume:.1f}ä¸‡æ‰‹)')
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
            title = f"{stock_name}({stock_code}) æœ€è¿‘30å¤©æˆäº¤é‡èµ°åŠ¿\n"
            title += f"å½“å‰ä»·æ ¼: {stock_info['current_price']:.2f}å…ƒ | "
            title += f"æ¶¨è·Œå¹…: {stock_info['change_pct']:+.2f}% | "
            title += f"å¼‚å¸¸è¯„åˆ†: {stock_info['anomaly_score']:.1f}"
            
            ax.set_title(title, fontsize=14, fontweight='bold', pad=20)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12)
            ax.set_ylabel('æˆäº¤é‡ (ä¸‡æ‰‹)', fontsize=12)
            
            # æ ¼å¼åŒ–Xè½´æ—¥æœŸ
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
            ax.xaxis.set_major_locator(mdates.DayLocator(interval=5))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
            
            # æ·»åŠ ç½‘æ ¼
            ax.grid(True, alpha=0.3)
            
            # æ·»åŠ å›¾ä¾‹
            ax.legend(loc='upper left')
            
            # åœ¨ä»Šå¤©çš„æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡æ³¨
            today_bar = bars[-1]
            height = today_bar.get_height()
            ax.text(today_bar.get_x() + today_bar.get_width()/2., height + max(volumes)*0.02,
                   f'{height:.1f}',
                   ha='center', va='bottom', fontweight='bold', fontsize=10)
            
            # æ·»åŠ çªç ´æ ‡æ³¨
            anomaly_types = stock_info['anomaly_type'].split(',')
            annotation_text = "çªç ´ç±»å‹: " + ", ".join(anomaly_types)
            if stock_info['is_historical_high']:
                annotation_text += "\nğŸ”¥ åˆ›60å¤©æ–°é«˜ï¼"
            
            ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,
                   fontsize=10, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            filename = f"{self.chart_dir}/{stock_code}_{stock_name}_æˆäº¤é‡å¼‚å¸¸.png"
            # å¤„ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
            filename = filename.replace('/', '_').replace('\\', '_').replace('*', '_')
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"ğŸ“Š å·²ç”Ÿæˆå›¾è¡¨: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆè‚¡ç¥¨ {stock_info.get('code', 'unknown')} å›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def analyze_volume_anomaly(self, stock_info):
        """åˆ†æå•åªè‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            stock_code = stock_info['code']
            stock_name = stock_info['name']
            today_volume = stock_info['today_volume']
            
            # è¿‡æ»¤æˆäº¤é‡å¤ªå°çš„è‚¡ç¥¨
            if today_volume < self.min_volume:
                return None
            
            # è¿‡æ»¤æ¶¨å¹…ä¸å¤Ÿçš„è‚¡ç¥¨
            if stock_info['change_pct'] < self.min_change_pct:
                return None
            
            # è·å–å†å²Kçº¿æ•°æ®
            kline_data = self.get_stock_kline_data(stock_code, days=61)
            
            if len(kline_data) < 61:
                return None
            
            # æ•°æ®åˆ†ç¦»ï¼šå‰60å¤©å†å² + ä»Šå¤©
            historical_60 = kline_data[:-1]
            today_data = kline_data[-1]
            
            # è®¾å®šé˜ˆå€¼
            strict_threshold = today_volume * self.strict_threshold
            loose_threshold = today_volume * self.loose_threshold
            
            # æ£€æŸ¥å†å²çªç ´æƒ…å†µ
            over_strict_days = [d for d in historical_60 if d['volume'] > strict_threshold]
            over_loose_days = [d for d in historical_60 if d['volume'] > loose_threshold]
            
            # æ£€æŸ¥æœ€è¿‘15å¤©çš„æƒ…å†µ
            recent_15 = historical_60[-self.recent_days:]
            over_strict_recent = [d for d in recent_15 if d['volume'] > strict_threshold]
            over_loose_recent = [d for d in recent_15 if d['volume'] > loose_threshold]
            
            # ä¼˜åŒ–çš„å¼‚å¸¸åˆ¤æ–­æ ‡å‡†
            # æ–¹æ¡ˆ1ï¼šä¸¥æ ¼æ¨¡å¼ - å‰60å¤©å®Œå…¨æ²¡è¶…è¿‡50%é˜ˆå€¼
            is_strict_anomaly = len(over_strict_days) == 0
            
            # æ–¹æ¡ˆ2ï¼šå®½æ¾æ¨¡å¼ - å‰60å¤©â‰¤2å¤©è¶…è¿‡60%é˜ˆå€¼ ä¸” æœ€è¿‘15å¤©â‰¤1å¤©è¶…è¿‡50%é˜ˆå€¼
            is_loose_anomaly = (
                len(over_loose_days) <= 2 and
                len(over_strict_recent) <= 1
            )
            
            # æ–¹æ¡ˆ3ï¼šè¿‘æœŸçªç ´ - æœ€è¿‘15å¤©æ²¡è¶…è¿‡é˜ˆå€¼ï¼Œä»Šå¤©çªç ´
            is_recent_breakthrough = len(over_strict_recent) == 0
            
            # ç»¼åˆåˆ¤æ–­
            is_anomaly = is_strict_anomaly or is_loose_anomaly or is_recent_breakthrough
            
            if is_anomaly:
                # è®¡ç®—å¼‚å¸¸è¯„åˆ†
                historical_max = max(d['volume'] for d in historical_60)
                recent_max = max(d['volume'] for d in recent_15)
                
                # è¯„åˆ†å› å­
                breakthrough_score = 0
                if is_strict_anomaly:
                    breakthrough_score += 50  # ä¸¥æ ¼çªç ´æœ€é«˜åˆ†
                if is_recent_breakthrough:
                    breakthrough_score += 30  # è¿‘æœŸçªç ´åŠ åˆ†
                if is_loose_anomaly:
                    breakthrough_score += 20  # å®½æ¾çªç ´åŸºç¡€åˆ†
                
                volume_score = min(30, (today_volume / strict_threshold) * 10)  # æˆäº¤é‡å€æ•°åˆ†
                price_score = min(20, stock_info['change_pct'] * 5)  # æ¶¨å¹…åˆ†
                
                anomaly_score = breakthrough_score + volume_score + price_score
                
                # åˆ¤æ–­å¼‚å¸¸ç±»å‹
                anomaly_type = []
                if is_strict_anomaly:
                    anomaly_type.append("ä¸¥æ ¼çªç ´")
                if is_recent_breakthrough:
                    anomaly_type.append("è¿‘æœŸçªç ´")
                if is_loose_anomaly:
                    anomaly_type.append("å®½æ¾çªç ´")
                
                anomaly_info = {
                    'code': stock_code,
                    'name': stock_name,
                    'current_price': stock_info['current_price'],
                    'change_pct': stock_info['change_pct'],
                    'today_volume': today_volume,
                    'strict_threshold': strict_threshold,
                    'loose_threshold': loose_threshold,
                    'historical_max': historical_max,
                    'recent_max': recent_max,
                    'over_strict_days': len(over_strict_days),
                    'over_loose_days': len(over_loose_days),
                    'over_strict_recent': len(over_strict_recent),
                    'anomaly_score': anomaly_score,
                    'anomaly_type': ','.join(anomaly_type),
                    'turnover': stock_info['turnover'],
                    'is_historical_high': today_volume > historical_max,
                    'kline_data': kline_data  # ä¿å­˜Kçº¿æ•°æ®ç”¨äºç”Ÿæˆå›¾è¡¨
                }
                
                return anomaly_info
            
            return None
            
        except Exception as e:
            logger.debug(f"åˆ†æè‚¡ç¥¨ {stock_info.get('code', 'unknown')} å¼‚å¸¸å¤±è´¥: {str(e)}")
            return None
    
    def process_single_stock(self, stock):
        """å¤„ç†å•åªè‚¡ç¥¨"""
        try:
            anomaly = self.analyze_volume_anomaly(stock)
            
            with self.lock:
                self.processed_count += 1
                
                if anomaly:
                    self.anomaly_stocks.append(anomaly)
                    extra_info = f"å‘ç°å¼‚å¸¸: {anomaly['name']}({anomaly['code']}) - è¯„åˆ†:{anomaly['anomaly_score']:.1f}"
                    self._show_progress(self.processed_count, len(self.all_stocks), extra_info)
                else:
                    if self.processed_count % 50 == 0:
                        self._show_progress(self.processed_count, len(self.all_stocks))
                
                self._random_delay()
                
        except Exception as e:
            logger.debug(f"å¤„ç†è‚¡ç¥¨å¤±è´¥: {str(e)}")
    
    def detect_all_anomalies(self, limit=None):
        """æ£€æµ‹æ‰€æœ‰è‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ£€æµ‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸...")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            self.all_stocks = self.get_shanghai_a_stocks()
            if not self.all_stocks:
                logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return
            
            # é¢„ç­›é€‰ï¼šä¼˜å…ˆæ£€æµ‹æ´»è·ƒè‚¡ç¥¨
            active_stocks = [s for s in self.all_stocks if s.get('today_volume', 0) >= self.min_volume and s.get('change_pct', 0) >= self.min_change_pct]
            active_stocks.sort(key=lambda x: x.get('today_volume', 0), reverse=True)
            
            # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            if limit:
                active_stocks = active_stocks[:limit]
                logger.info(f"âš¡ æµ‹è¯•æ¨¡å¼ï¼šé™åˆ¶å¤„ç†å‰ {limit} åªè‚¡ç¥¨")
            
            logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ {len(active_stocks)} åªæ´»è·ƒè‚¡ç¥¨...")
            self.all_stocks = active_stocks  # æ›´æ–°å¼•ç”¨
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = [executor.submit(self.process_single_stock, stock) for stock in active_stocks]
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                concurrent.futures.wait(futures)
            
            # æŒ‰å¼‚å¸¸è¯„åˆ†æ’åº
            self.anomaly_stocks.sort(key=lambda x: x['anomaly_score'], reverse=True)
            
            elapsed_time = time.time() - self.start_time
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼ç”¨æ—¶ {elapsed_time/60:.1f} åˆ†é’Ÿ")
            logger.info(f"ğŸ“Š å…±åˆ†æ {self.processed_count} åªè‚¡ç¥¨ï¼Œå‘ç° {len(self.anomaly_stocks)} åªå¼‚å¸¸è‚¡ç¥¨")
            
        except Exception as e:
            logger.error(f"æ£€æµ‹æˆäº¤é‡å¼‚å¸¸å¤±è´¥: {str(e)}")
    
    def generate_all_charts(self):
        """ä¸ºæ‰€æœ‰å¼‚å¸¸è‚¡ç¥¨ç”Ÿæˆå›¾è¡¨"""
        try:
            if not self.anomaly_stocks:
                logger.info("æ²¡æœ‰å¼‚å¸¸è‚¡ç¥¨ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
                return
            
            logger.info(f"ğŸ“Š å¼€å§‹ä¸º {len(self.anomaly_stocks)} åªå¼‚å¸¸è‚¡ç¥¨ç”Ÿæˆæˆäº¤é‡å›¾è¡¨...")
            
            chart_files = []
            for i, stock in enumerate(self.anomaly_stocks, 1):
                try:
                    logger.info(f"ğŸ“ˆ ç”Ÿæˆå›¾è¡¨ {i}/{len(self.anomaly_stocks)}: {stock['name']}({stock['code']})")
                    
                    chart_file = self.generate_volume_chart(stock, stock['kline_data'])
                    if chart_file:
                        chart_files.append(chart_file)
                        
                    # æ¸…ç†Kçº¿æ•°æ®ï¼ŒèŠ‚çœå†…å­˜
                    del stock['kline_data']
                    
                except Exception as e:
                    logger.error(f"ç”Ÿæˆè‚¡ç¥¨ {stock['code']} å›¾è¡¨å¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(chart_files)} ä¸ªå›¾è¡¨ï¼Œä¿å­˜åœ¨ {self.chart_dir} ç›®å½•")
            return chart_files
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def save_results(self, filename=None):
        """ä¿å­˜æ£€æµ‹ç»“æœ"""
        try:
            if not self.anomaly_stocks:
                logger.warning("æ²¡æœ‰å¼‚å¸¸è‚¡ç¥¨æ•°æ®å¯ä¿å­˜")
                return None
            
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨_{timestamp}.xlsx"
            
            # åˆ›å»ºDataFrameå‰å…ˆæ¸…ç†Kçº¿æ•°æ®
            clean_stocks = []
            for stock in self.anomaly_stocks:
                clean_stock = stock.copy()
                if 'kline_data' in clean_stock:
                    del clean_stock['kline_data']  # ç§»é™¤Kçº¿æ•°æ®ï¼ŒExcelä¸éœ€è¦
                clean_stocks.append(clean_stock)
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(clean_stocks)
            
            # é‡å‘½ååˆ—
            column_names = {
                'code': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'current_price': 'å½“å‰ä»·æ ¼',
                'change_pct': 'æ¶¨è·Œå¹…(%)',
                'today_volume': 'ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)',
                'strict_threshold': 'ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)',
                'loose_threshold': 'å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)',
                'historical_max': '60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)',
                'recent_max': '15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)',
                'over_strict_days': 'è¶…ä¸¥æ ¼é˜ˆå€¼å¤©æ•°',
                'over_loose_days': 'è¶…å®½æ¾é˜ˆå€¼å¤©æ•°',
                'over_strict_recent': 'è¿‘æœŸè¶…é˜ˆå€¼å¤©æ•°',
                'anomaly_score': 'å¼‚å¸¸è¯„åˆ†',
                'anomaly_type': 'å¼‚å¸¸ç±»å‹',
                'is_historical_high': 'æ˜¯å¦åˆ›æ–°é«˜',
                'turnover': 'æˆäº¤é¢(å…ƒ)'
            }
            
            df = df.rename(columns=column_names)
            
            # æ ¼å¼åŒ–æ•°å€¼æ˜¾ç¤º
            df['æ¶¨è·Œå¹…(%)'] = df['æ¶¨è·Œå¹…(%)'].round(2)
            df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'] = df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'].round(1)
            df['ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)'] = df['ä¸¥æ ¼é˜ˆå€¼(ä¸‡æ‰‹)'].round(1)
            df['å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)'] = df['å®½æ¾é˜ˆå€¼(ä¸‡æ‰‹)'].round(1)
            df['60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'] = df['60å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'].round(1)
            df['15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'] = df['15å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'].round(1)
            df['å¼‚å¸¸è¯„åˆ†'] = df['å¼‚å¸¸è¯„åˆ†'].round(1)
            
            # ä¿å­˜åˆ°Excel
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨', index=False)
                
                # è°ƒæ•´åˆ—å®½
                worksheet = writer.sheets['æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨']
                for column in worksheet.columns:
                    max_length = 0
                    column = [cell for cell in column]
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 25)
                    worksheet.column_dimensions[column[0].column_letter].width = adjusted_width
            
            logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def print_summary(self):
        """æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦"""
        if not self.anomaly_stocks:
            logger.info("ğŸ“Š æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å¼‚å¸¸æˆäº¤é‡è‚¡ç¥¨")
            return
        
        logger.info("ğŸ“Š æˆäº¤é‡å¼‚å¸¸æ£€æµ‹ç»“æœæ‘˜è¦:")
        logger.info(f"   ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°é‡: {len(self.anomaly_stocks)}")
        
        # ç»Ÿè®¡å¼‚å¸¸ç±»å‹
        type_count = {}
        for stock in self.anomaly_stocks:
            types = stock['anomaly_type'].split(',')
            for t in types:
                type_count[t] = type_count.get(t, 0) + 1
        
        logger.info(f"   å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
        for anomaly_type, count in type_count.items():
            logger.info(f"     {anomaly_type}: {count}åª")
        
        # æ˜¾ç¤ºå‰10åªå¼‚å¸¸è¯„åˆ†æœ€é«˜çš„è‚¡ç¥¨
        top_stocks = self.anomaly_stocks[:10]
        logger.info("\nğŸ† å¼‚å¸¸è¯„åˆ†TOP10è‚¡ç¥¨:")
        
        for i, stock in enumerate(top_stocks, 1):
            logger.info(f"   {i:2d}. {stock['name']}({stock['code']})")
            logger.info(f"       ä»·æ ¼: {stock['current_price']:.2f}å…ƒ æ¶¨å¹…: {stock['change_pct']:+.2f}%")
            logger.info(f"       ä»Šæ—¥é‡: {stock['today_volume']:.1f}ä¸‡æ‰‹ | é˜ˆå€¼: {stock['strict_threshold']:.1f}ä¸‡æ‰‹")
            logger.info(f"       ç±»å‹: {stock['anomaly_type']} | è¯„åˆ†: {stock['anomaly_score']:.1f}")
            if stock['is_historical_high']:
                logger.info(f"       ğŸ”¥ åˆ›60å¤©æ–°é«˜ï¼")
        
        # ç»Ÿè®¡ä¿¡æ¯
        avg_score = sum(s['anomaly_score'] for s in self.anomaly_stocks) / len(self.anomaly_stocks)
        max_score = max(s['anomaly_score'] for s in self.anomaly_stocks)
        high_count = sum(1 for s in self.anomaly_stocks if s['is_historical_high'])
        
        logger.info(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   å¹³å‡å¼‚å¸¸è¯„åˆ†: {avg_score:.1f}")
        logger.info(f"   æœ€é«˜å¼‚å¸¸è¯„åˆ†: {max_score:.1f}")
        logger.info(f"   åˆ›æ–°é«˜è‚¡ç¥¨æ•°: {high_count}åª")
        logger.info(f"   å›¾è¡¨ä¿å­˜ç›®å½•: {self.chart_dir}")

def main():
    """ä¸»å‡½æ•°"""
    workflow = VolumeAnomalyWorkflow(request_delay=0.1, max_workers=3)
    
    try:
        logger.info("ğŸš€ å¼€å§‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹å·¥ä½œæµ...")
        
        # æ£€æµ‹æ‰€æœ‰å¼‚å¸¸
        # æµ‹è¯•æ—¶å¯ä»¥è®¾ç½®limit=100é™åˆ¶æ•°é‡ï¼Œæ­£å¼è¿è¡Œæ—¶å»æ‰limitå‚æ•°
        workflow.detect_all_anomalies(limit=200)  # æµ‹è¯•200åªæ´»è·ƒè‚¡ç¥¨
        
        # ç”Ÿæˆå›¾è¡¨
        if workflow.anomaly_stocks:
            chart_files = workflow.generate_all_charts()
            logger.info(f"ğŸ“Š å›¾è¡¨æ–‡ä»¶å·²ä¿å­˜åˆ°: {workflow.chart_dir}")
        
        # æ‰“å°æ‘˜è¦
        workflow.print_summary()
        
        # ä¿å­˜ç»“æœ
        filename = workflow.save_results()
        
        if filename:
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼")
            logger.info(f"ğŸ“‹ Excelç»“æœ: {filename}")
            logger.info(f"ğŸ“Š å›¾è¡¨ç›®å½•: {workflow.chart_dir}")
            logger.info(f"ğŸ’¡ å¯ä»¥ç›´æ¥æ‰“å¼€å›¾è¡¨æ–‡ä»¶æŸ¥çœ‹æˆäº¤é‡èµ°åŠ¿")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        # å³ä½¿ä¸­æ–­ä¹Ÿä¿å­˜å·²å¤„ç†çš„ç»“æœ
        if workflow.anomaly_stocks:
            filename = workflow.save_results()
            logger.info(f"ğŸ’¾ å·²ä¿å­˜éƒ¨åˆ†ç»“æœåˆ°: {filename}")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()