#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹çˆ¬è™«
ç­–ç•¥ï¼šæ‰¾å‡ºå½“æ—¥æˆäº¤é‡ç›¸æ¯”è¿‡å»30å¤©å‡å€¼æ˜æ˜¾å¼‚å¸¸æ”¾å¤§çš„è‚¡ç¥¨
é€‚ç”¨äºçŸ­çº¿äº¤æ˜“æœºä¼šè¯†åˆ«
"""

import requests
import re
import json
import time
import random
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import statistics

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('volume_anomaly.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VolumeAnomalyDetector:
    def __init__(self, request_delay=0.1):  # å‡å°‘å»¶è¿Ÿåˆ°0.1ç§’
        """åˆå§‹åŒ–æˆäº¤é‡å¼‚å¸¸æ£€æµ‹å™¨"""
        self.request_delay = request_delay
        self.session = requests.Session()
        
        # User-Agentæ± 
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        ]
        
        self._update_session_headers()
        
        # å­˜å‚¨ç»“æœ
        self.anomaly_stocks = []
        
        # æ£€æµ‹å‚æ•° - æ›´ä¸¥æ ¼çš„æ ‡å‡†
        self.volume_threshold = 3.0      # æˆäº¤é‡å€æ•°é˜ˆå€¼æé«˜åˆ°3å€
        self.min_avg_volume = 10.0       # æœ€å°å¹³å‡æˆäº¤é‡æé«˜åˆ°10ä¸‡æ‰‹
        self.analysis_days = 30          # åˆ†æè¿‡å»30å¤©çš„æ•°æ®
        self.max_volume_multiplier = 1.5 # è¶…è¿‡30å¤©æœ€å¤§å€¼çš„1.5å€ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        self.min_z_score = 2.5           # Z-Scoreæœ€å°å€¼æé«˜åˆ°2.5
        
        # æ€§èƒ½ç»Ÿè®¡
        self.start_time = time.time()
        self.processed_count = 0
    
    def _get_random_user_agent(self):
        """è·å–éšæœºUser-Agent"""
        return random.choice(self.user_agents)
    
    def _update_session_headers(self):
        """æ›´æ–°session headers"""
        self.session.headers.update({
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'application/javascript, */*;q=0.1',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'http://quote.eastmoney.com/',
        })
    
    def _random_delay(self):
        """éšæœºå»¶è¿Ÿ"""
        delay = random.uniform(self.request_delay * 0.8, self.request_delay * 1.2)  # å‡å°‘å»¶è¿ŸèŒƒå›´
        time.sleep(delay)
        self._update_session_headers()
    
    def _show_progress(self, current, total, extra_info=""):
        """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        if current > 0:
            eta = (elapsed / current) * (total - current)
            eta_str = f"é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ"
        else:
            eta_str = "è®¡ç®—ä¸­..."
        
        percentage = (current / total) * 100 if total > 0 else 0
        
        # æ¯10ä¸ªæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼Œæˆ–è€…å‘ç°å¼‚å¸¸æ—¶æ˜¾ç¤º
        if current % 10 == 0 or "å‘ç°å¼‚å¸¸" in extra_info or current == total:
            logger.info(f"ğŸ“Š è¿›åº¦: {current}/{total} ({percentage:.1f}%) | ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | {eta_str} | {extra_info}")
            
            # å¦‚æœæ˜¯å‘ç°å¼‚å¸¸ï¼Œä¹Ÿåœ¨æ§åˆ¶å°æ˜¾ç¤º
            if "å‘ç°å¼‚å¸¸" in extra_info:
                print(f"ğŸš¨ {extra_info}")
    
    def _quick_filter_stocks(self, stocks):
        """å¿«é€Ÿè¿‡æ»¤è‚¡ç¥¨ï¼Œä¼˜å…ˆæ£€æµ‹æ´»è·ƒè‚¡ç¥¨"""
        logger.info("ğŸ” é¢„ç­›é€‰æ´»è·ƒè‚¡ç¥¨...")
        
        # æŒ‰ä»Šæ—¥æˆäº¤é‡æ’åºï¼Œä¼˜å…ˆæ£€æµ‹æˆäº¤é‡å¤§çš„è‚¡ç¥¨
        active_stocks = [s for s in stocks if s.get('today_volume', 0) >= 3.0]  # æˆäº¤é‡>=3ä¸‡æ‰‹
        active_stocks.sort(key=lambda x: x.get('today_volume', 0), reverse=True)
        
        # å…¶ä»–è‚¡ç¥¨
        other_stocks = [s for s in stocks if s.get('today_volume', 0) < 3.0]
        
        logger.info(f"æ´»è·ƒè‚¡ç¥¨: {len(active_stocks)}åª, å…¶ä»–è‚¡ç¥¨: {len(other_stocks)}åª")
        
        # å…ˆæ£€æµ‹æ´»è·ƒè‚¡ç¥¨ï¼Œå†æ£€æµ‹å…¶ä»–è‚¡ç¥¨
        return active_stocks + other_stocks
    
    def _extract_jsonp_data(self, response_text):
        """ä»JSONPå“åº”ä¸­æå–JSONæ•°æ®"""
        try:
            pattern = r'[a-zA-Z_$][a-zA-Z0-9_$]*\((.*)\)'
            match = re.search(pattern, response_text)
            if match:
                json_str = match.group(1)
                return json.loads(json_str)
            return None
        except Exception as e:
            logger.error(f"è§£æJSONPæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def get_shanghai_a_stocks(self):
        """è·å–æ‰€æœ‰ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨"""
        try:
            logger.info("ğŸ” å¼€å§‹è·å–ä¸Šæµ·Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            all_stocks = []
            
            # è·å–æ€»é¡µæ•°
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            # å…ˆè·å–ç¬¬ä¸€é¡µæ¥ç¡®å®šæ€»æ•°
            url = "https://push2.eastmoney.com/api/qt/clist/get"
            params = {
                'np': '1',
                'fltt': '1',
                'invt': '2',
                'cb': callback,
                'fs': 'm:1+t:2,m:1+t:23',  # ä¸Šæµ·Aè‚¡
                'fields': 'f12,f13,f14,f1,f2,f4,f3,f152,f5,f6,f7,f15,f18,f16,f17,f10,f8,f9,f23',
                'fid': 'f3',
                'pn': '1',
                'pz': '50',  # å¢åŠ æ¯é¡µæ•°é‡åˆ°50
                'po': '1',
                'dect': '1',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'wbp2u': f'{random.randint(10**15, 10**16-1)}|0|1|0|web',
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=15)  # å‡å°‘è¶…æ—¶æ—¶é—´
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                logger.error("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
                return []
            
            total_count = data.get('data', {}).get('total', 0)
            page_size = 50
            total_pages = (total_count + page_size - 1) // page_size
            
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_count}, æ€»é¡µæ•°: {total_pages}")
            
            # è·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®
            for page in range(1, min(total_pages + 1, 50)):  # é™åˆ¶æœ€å¤š50é¡µï¼ŒåŠ å¿«é€Ÿåº¦
                try:
                    if page % 10 == 1:  # æ¯10é¡µæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        logger.info(f"ğŸ“„ è·å–è‚¡ç¥¨åˆ—è¡¨ç¬¬ {page}/{min(total_pages, 50)} é¡µ...")
                    
                    timestamp = int(time.time() * 1000)
                    callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
                    
                    params.update({
                        'cb': callback,
                        'pn': str(page),
                        '_': str(timestamp + random.randint(1, 100))
                    })
                    
                    response = self.session.get(url, params=params, timeout=15)
                    response.raise_for_status()
                    
                    data = self._extract_jsonp_data(response.text)
                    if not data or data.get('rc') != 0:
                        logger.warning(f"ç¬¬ {page} é¡µæ•°æ®è·å–å¤±è´¥")
                        continue
                    
                    stocks = data.get('data', {}).get('diff', [])
                    
                    for stock in stocks:
                        stock_code = stock.get('f12', '')  # è‚¡ç¥¨ä»£ç 
                        stock_name = stock.get('f14', '')  # è‚¡ç¥¨åç§°
                        current_price = stock.get('f2', 0) / 100 if stock.get('f2') else 0  # å½“å‰ä»·æ ¼(åˆ†->å…ƒ)
                        change_pct = stock.get('f3', 0) / 100 if stock.get('f3') else 0     # æ¶¨è·Œå¹…(%)
                        volume = stock.get('f5', 0)  # æˆäº¤é‡(æ‰‹)
                        turnover = stock.get('f6', 0)  # æˆäº¤é¢(å…ƒ)
                        
                        if stock_code and stock_name:
                            stock_info = {
                                'code': stock_code,
                                'name': stock_name,
                                'current_price': current_price,
                                'change_pct': change_pct,
                                'today_volume': volume / 100,  # è½¬æ¢ä¸ºä¸‡æ‰‹
                                'turnover': turnover
                            }
                            all_stocks.append(stock_info)
                    
                    # å‡å°‘å»¶è¿Ÿ
                    time.sleep(0.05)  # åªå»¶è¿Ÿ50æ¯«ç§’
                    
                except Exception as e:
                    logger.error(f"è·å–ç¬¬ {page} é¡µå¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(all_stocks)} åªä¸Šæµ·Aè‚¡")
            return all_stocks
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šæµ·Aè‚¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def get_stock_kline_data(self, stock_code, days=45):
        """è·å–è‚¡ç¥¨Kçº¿æ•°æ®ï¼ˆåŒ…å«æˆäº¤é‡ï¼‰"""
        try:
            # æ„é€ Kçº¿æ•°æ®APIè¯·æ±‚
            timestamp = int(time.time() * 1000)
            callback = f"jQuery{random.randint(10**20, 10**21-1)}_{timestamp}"
            
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                'fields1': 'f1,f2,f3,f4,f5',
                'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61',
                'fqt': '1',  # å‰å¤æƒ
                'end': '29991010',
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'cb': callback,
                'klt': '101',  # æ—¥Kçº¿
                'secid': f'1.{stock_code}',  # ä¸Šæµ·Aè‚¡
                'lmt': str(days),  # è·å–æœ€è¿‘dayså¤©çš„æ•°æ®
                '_': str(timestamp + random.randint(1, 100))
            }
            
            response = self.session.get(url, params=params, timeout=10)  # å‡å°‘è¶…æ—¶æ—¶é—´
            response.raise_for_status()
            
            data = self._extract_jsonp_data(response.text)
            if not data or data.get('rc') != 0:
                return []
            
            klines = data.get('data', {}).get('klines', [])
            
            # è§£æKçº¿æ•°æ®
            parsed_data = []
            for kline in klines:
                parts = kline.split(',')
                if len(parts) >= 6:
                    try:
                        date = parts[0]
                        open_price = float(parts[1])
                        close_price = float(parts[2])
                        high_price = float(parts[3])
                        low_price = float(parts[4])
                        volume = float(parts[5])  # æˆäº¤é‡(æ‰‹)
                        turnover = float(parts[6]) if len(parts) > 6 else 0  # æˆäº¤é¢
                        
                        parsed_data.append({
                            'date': date,
                            'open': open_price,
                            'close': close_price,
                            'high': high_price,
                            'low': low_price,
                            'volume': volume / 100,  # è½¬æ¢ä¸ºä¸‡æ‰‹
                            'turnover': turnover
                        })
                    except (ValueError, IndexError):
                        continue
            
            return parsed_data
            
        except Exception as e:
            logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} Kçº¿æ•°æ®å¤±è´¥: {str(e)}")  # æ”¹ä¸ºdebugçº§åˆ«
            return []
    
    def analyze_volume_anomaly(self, stock_info):
        """åˆ†æå•åªè‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            stock_code = stock_info['code']
            stock_name = stock_info['name']
            today_volume = stock_info['today_volume']
            
            # è·å–å†å²Kçº¿æ•°æ®
            kline_data = self.get_stock_kline_data(stock_code, days=self.analysis_days + 10)
            
            if len(kline_data) < self.analysis_days:
                logger.debug(f"è‚¡ç¥¨ {stock_code} å†å²æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                return None
            
            # å–æœ€è¿‘analysis_dayså¤©çš„æ•°æ®ï¼ˆä¸åŒ…æ‹¬ä»Šå¤©ï¼‰
            recent_data = kline_data[-(self.analysis_days+1):-1]  # æœ€è¿‘30å¤©ï¼Œä¸åŒ…æ‹¬ä»Šå¤©
            
            if len(recent_data) < self.analysis_days:
                return None
            
            # è®¡ç®—è¿‡å»30å¤©çš„æˆäº¤é‡ç»Ÿè®¡
            volumes = [day['volume'] for day in recent_data]
            avg_volume = statistics.mean(volumes)
            median_volume = statistics.median(volumes)
            max_volume = max(volumes)
            min_volume = min(volumes)
            
            # è®¡ç®—æ ‡å‡†å·®
            try:
                std_volume = statistics.stdev(volumes) if len(volumes) > 1 else 0
            except:
                std_volume = 0
            
            # è¿‡æ»¤æ‰å¹³å‡æˆäº¤é‡å¤ªå°çš„è‚¡ç¥¨
            if avg_volume < self.min_avg_volume:
                return None
            
            # è®¡ç®—å¼‚å¸¸æŒ‡æ ‡
            volume_ratio = today_volume / avg_volume if avg_volume > 0 else 0
            volume_vs_max = today_volume / max_volume if max_volume > 0 else 0
            
            # Z-scoreè®¡ç®—ï¼ˆæ ‡å‡†åŒ–è·ç¦»ï¼‰
            z_score = (today_volume - avg_volume) / std_volume if std_volume > 0 else 0
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå¼‚å¸¸æˆäº¤é‡
            is_anomaly = (
                volume_ratio >= self.volume_threshold and  # æˆäº¤é‡å€æ•°è¾¾åˆ°é˜ˆå€¼
                today_volume > max_volume * 1.2 and        # è¶…è¿‡30å¤©æœ€å¤§å€¼çš„1.2å€
                z_score > 2.0 and                          # Z-scoreå¤§äº2ï¼ˆç»Ÿè®¡å­¦å¼‚å¸¸ï¼‰
                stock_info['change_pct'] > 0               # è‚¡ä»·ä¸Šæ¶¨
            )
            
            if is_anomaly:
                anomaly_info = {
                    'code': stock_code,
                    'name': stock_name,
                    'current_price': stock_info['current_price'],
                    'change_pct': stock_info['change_pct'],
                    'today_volume': today_volume,
                    'avg_30d_volume': avg_volume,
                    'max_30d_volume': max_volume,
                    'volume_ratio': volume_ratio,
                    'volume_vs_max': volume_vs_max,
                    'z_score': z_score,
                    'turnover': stock_info['turnover'],
                    
                    # è®¡ç®—å¼‚å¸¸å¼ºåº¦è¯„åˆ†ï¼ˆ0-100ï¼‰
                    'anomaly_score': min(100, 
                        (volume_ratio * 20) +           # å€æ•°å¾—åˆ†
                        (z_score * 10) +                # ç»Ÿè®¡å¼‚å¸¸å¾—åˆ†  
                        (stock_info['change_pct'] * 2)  # æ¶¨å¹…å¾—åˆ†
                    )
                }
                
                logger.info(f"ğŸš¨ å‘ç°å¼‚å¸¸: {stock_name}({stock_code})")
                logger.info(f"   ä»Šæ—¥æˆäº¤é‡: {today_volume:.1f}ä¸‡æ‰‹")
                logger.info(f"   30å¤©å‡é‡: {avg_volume:.1f}ä¸‡æ‰‹")
                logger.info(f"   æˆäº¤é‡å€æ•°: {volume_ratio:.2f}x")
                logger.info(f"   æ¶¨è·Œå¹…: {stock_info['change_pct']:.2f}%")
                logger.info(f"   å¼‚å¸¸è¯„åˆ†: {anomaly_info['anomaly_score']:.1f}")
                
                return anomaly_info
            
            return None
            
        except Exception as e:
            logger.error(f"åˆ†æè‚¡ç¥¨ {stock_info.get('code', 'unknown')} å¼‚å¸¸å¤±è´¥: {str(e)}")
            return None
    
    def detect_all_anomalies(self, limit=None):
        """æ£€æµ‹æ‰€æœ‰è‚¡ç¥¨çš„æˆäº¤é‡å¼‚å¸¸"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ£€æµ‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸...")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stocks = self.get_shanghai_a_stocks()
            if not stocks:
                logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return
            
            # é¢„ç­›é€‰æ´»è·ƒè‚¡ç¥¨
            stocks = self._quick_filter_stocks(stocks)
            
            # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            if limit:
                stocks = stocks[:limit]
                logger.info(f"âš¡ æµ‹è¯•æ¨¡å¼ï¼šé™åˆ¶å¤„ç†å‰ {limit} åªè‚¡ç¥¨")
            
            total_stocks = len(stocks)
            logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ {total_stocks} åªè‚¡ç¥¨...")
            
            # åˆ†ææ¯åªè‚¡ç¥¨
            for i, stock in enumerate(stocks, 1):
                try:
                    self.processed_count = i
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress_info = f"{stock['code']} - {stock['name']}"
                    if stock['today_volume'] >= 10:  # é«˜æˆäº¤é‡è‚¡ç¥¨ç‰¹åˆ«æ ‡æ³¨
                        progress_info += f" (æˆäº¤é‡:{stock['today_volume']:.1f}ä¸‡æ‰‹)"
                    
                    self._show_progress(i, total_stocks, progress_info)
                    
                    # åˆ†ææˆäº¤é‡å¼‚å¸¸
                    anomaly = self.analyze_volume_anomaly(stock)
                    
                    if anomaly:
                        self.anomaly_stocks.append(anomaly)
                        # å®æ—¶æ˜¾ç¤ºå‘ç°çš„å¼‚å¸¸è‚¡ç¥¨
                        extra_info = f"ğŸš¨ å‘ç°å¼‚å¸¸: {anomaly['name']}({anomaly['code']}) - å€æ•°:{anomaly['volume_ratio']:.2f}x, è¯„åˆ†:{anomaly['anomaly_score']:.1f}"
                        self._show_progress(i, total_stocks, extra_info)
                    
                    # å‡å°‘å»¶è¿Ÿ
                    if i % 20 == 0:  # æ¯20ä¸ªè‚¡ç¥¨å»¶è¿Ÿä¸€æ¬¡
                        self._random_delay()
                    
                except Exception as e:
                    logger.debug(f"å¤„ç†è‚¡ç¥¨ {stock.get('code', '')} å¤±è´¥: {str(e)}")
                    continue
            
            # æŒ‰å¼‚å¸¸è¯„åˆ†æ’åº
            self.anomaly_stocks.sort(key=lambda x: x['anomaly_score'], reverse=True)
            
            elapsed_time = time.time() - self.start_time
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼ç”¨æ—¶ {elapsed_time/60:.1f} åˆ†é’Ÿ")
            logger.info(f"ğŸ“Š å…±åˆ†æ {self.processed_count} åªè‚¡ç¥¨ï¼Œå‘ç° {len(self.anomaly_stocks)} åªå¼‚å¸¸è‚¡ç¥¨")
            
        except Exception as e:
            logger.error(f"æ£€æµ‹æˆäº¤é‡å¼‚å¸¸å¤±è´¥: {str(e)}")
    
    def save_results(self, filename=None):
        """ä¿å­˜æ£€æµ‹ç»“æœ"""
        try:
            if not self.anomaly_stocks:
                logger.warning("æ²¡æœ‰å¼‚å¸¸è‚¡ç¥¨æ•°æ®å¯ä¿å­˜")
                return None
            
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨_{timestamp}.xlsx"
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(self.anomaly_stocks)
            
            # é‡å‘½ååˆ—
            column_names = {
                'code': 'è‚¡ç¥¨ä»£ç ',
                'name': 'è‚¡ç¥¨åç§°',
                'current_price': 'å½“å‰ä»·æ ¼',
                'change_pct': 'æ¶¨è·Œå¹…(%)',
                'today_volume': 'ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)',
                'avg_30d_volume': '30å¤©å‡é‡(ä¸‡æ‰‹)',
                'max_30d_volume': '30å¤©æœ€å¤§é‡(ä¸‡æ‰‹)',
                'volume_ratio': 'æˆäº¤é‡å€æ•°',
                'volume_vs_max': 'ç›¸å¯¹æœ€å¤§é‡å€æ•°',
                'z_score': 'Z-Score',
                'anomaly_score': 'å¼‚å¸¸è¯„åˆ†',
                'turnover': 'æˆäº¤é¢(å…ƒ)'
            }
            
            df = df.rename(columns=column_names)
            
            # æ ¼å¼åŒ–æ•°å€¼æ˜¾ç¤º
            df['æ¶¨è·Œå¹…(%)'] = df['æ¶¨è·Œå¹…(%)'].round(2)
            df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'] = df['ä»Šæ—¥æˆäº¤é‡(ä¸‡æ‰‹)'].round(1)
            df['30å¤©å‡é‡(ä¸‡æ‰‹)'] = df['30å¤©å‡é‡(ä¸‡æ‰‹)'].round(1)
            df['30å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'] = df['30å¤©æœ€å¤§é‡(ä¸‡æ‰‹)'].round(1)
            df['æˆäº¤é‡å€æ•°'] = df['æˆäº¤é‡å€æ•°'].round(2)
            df['ç›¸å¯¹æœ€å¤§é‡å€æ•°'] = df['ç›¸å¯¹æœ€å¤§é‡å€æ•°'].round(2)
            df['Z-Score'] = df['Z-Score'].round(2)
            df['å¼‚å¸¸è¯„åˆ†'] = df['å¼‚å¸¸è¯„åˆ†'].round(1)
            
            # ä¿å­˜åˆ°Excel
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨', index=False)
                
                # è°ƒæ•´åˆ—å®½
                worksheet = writer.sheets['æˆäº¤é‡å¼‚å¸¸è‚¡ç¥¨']
                for column in worksheet.columns:
                    max_length = 0
                    column = [cell for cell in column]
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 30)
                    worksheet.column_dimensions[column[0].column_letter].width = adjusted_width
            
            logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def print_summary(self):
        """æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦"""
        if not self.anomaly_stocks:
            logger.info("ğŸ“Š æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å¼‚å¸¸æˆäº¤é‡è‚¡ç¥¨")
            return
        
        logger.info("ğŸ“Š æˆäº¤é‡å¼‚å¸¸æ£€æµ‹ç»“æœæ‘˜è¦:")
        logger.info(f"   ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ•°é‡: {len(self.anomaly_stocks)}")
        
        # æ˜¾ç¤ºå‰10åªå¼‚å¸¸è¯„åˆ†æœ€é«˜çš„è‚¡ç¥¨
        top_stocks = self.anomaly_stocks[:10]
        logger.info("\nğŸ† å¼‚å¸¸è¯„åˆ†TOP10è‚¡ç¥¨:")
        
        for i, stock in enumerate(top_stocks, 1):
            logger.info(f"   {i:2d}. {stock['name']}({stock['code']})")
            logger.info(f"       ä»·æ ¼: {stock['current_price']:.2f} æ¶¨å¹…: {stock['change_pct']:+.2f}%")
            logger.info(f"       ä»Šæ—¥é‡: {stock['today_volume']:.1f}ä¸‡æ‰‹ | 30å¤©å‡é‡: {stock['avg_30d_volume']:.1f}ä¸‡æ‰‹")
            logger.info(f"       æˆäº¤é‡å€æ•°: {stock['volume_ratio']:.2f}x | å¼‚å¸¸è¯„åˆ†: {stock['anomaly_score']:.1f}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        avg_ratio = sum(s['volume_ratio'] for s in self.anomaly_stocks) / len(self.anomaly_stocks)
        avg_score = sum(s['anomaly_score'] for s in self.anomaly_stocks) / len(self.anomaly_stocks)
        
        logger.info(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   å¹³å‡æˆäº¤é‡å€æ•°: {avg_ratio:.2f}x")
        logger.info(f"   å¹³å‡å¼‚å¸¸è¯„åˆ†: {avg_score:.1f}")
        logger.info(f"   æœ€é«˜å¼‚å¸¸è¯„åˆ†: {max(s['anomaly_score'] for s in self.anomaly_stocks):.1f}")

def main():
    """ä¸»å‡½æ•°"""
    detector = VolumeAnomalyDetector(request_delay=0.1)  # è¿›ä¸€æ­¥å‡å°‘å»¶è¿Ÿ
    
    try:
        logger.info("ğŸš€ å¼€å§‹ä¸Šæµ·Aè‚¡æˆäº¤é‡å¼‚å¸¸æ£€æµ‹...")
        
        # æ£€æµ‹æ‰€æœ‰å¼‚å¸¸
        # æµ‹è¯•æ—¶å¯ä»¥è®¾ç½®limit=50é™åˆ¶æ•°é‡ï¼Œæ­£å¼è¿è¡Œæ—¶å»æ‰limitå‚æ•°
        detector.detect_all_anomalies(limit=50)  # æµ‹è¯•50åªè‚¡ç¥¨
        
        # æ‰“å°æ‘˜è¦
        detector.print_summary()
        
        # ä¿å­˜ç»“æœ
        filename = detector.save_results()
        
        if filename:
            logger.info(f"ğŸ‰ æ£€æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        # å³ä½¿ä¸­æ–­ä¹Ÿä¿å­˜å·²å¤„ç†çš„ç»“æœ
        if detector.anomaly_stocks:
            filename = detector.save_results()
            logger.info(f"ğŸ’¾ å·²ä¿å­˜éƒ¨åˆ†ç»“æœåˆ°: {filename}")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()